import { ConversationService } from './ConversationService';
import { SupabaseService } from './SupabaseService';
import { ConversationContext, StartConversationRequest, AddMessageRequest, AIRule } from '../types/conversation';
import OpenAI from 'openai';


const ActivitySummaryJsonOutputSchema = {
  type: "object",
  properties: {
    // Pour ActivityDetailsStep
    shortDescription: {
      type: "string",
      description: "Description courte et accrocheuse de l'activit√©, mettant en avant ce qui la rend unique (max 200 caract√®res)"
    },
    longDescription: {
      type: "string", 
      description: "Description d√©taill√©e de l'activit√© expliquant le d√©roulement, l'approche et ce que vivront les participants (max 500 caract√®res)"
    },
    title: {
      type: "string",
      description: "Titre optimis√© et descriptif de l'activit√© (max 100 caract√®res)"
    },
    
    // Pour ActivityKeywordsStep
    selectedKeywords: {
      type: "array",
      items: { type: "string" },
      description: "Liste des mots-cl√©s les plus pertinents pour cette activit√©"
    },
    
    // Pour ActivitySummaryStep (uniquement benefits)
    benefits: {
      type: "array",
      items: { type: "string" },
      description: "Liste des b√©n√©fices concrets et mesurables que les participants peuvent attendre de cette activit√©"
    },
    
    // Nouveau champ pour d√©crire la situation id√©ale
    typicalSituations: {
      type: "string",
      description: "Description de la situation id√©ale d'un utilisateur qui serait √† m√™me de profiter pleinement de cette pratique. Inclure le profil psychologique, les exp√©riences v√©cues, les besoins sp√©cifiques, etc."
    }
  },
  required: ["shortDescription", "longDescription", "title", "selectedKeywords", "benefits", "typicalSituations"],
  additionalProperties: false
};


export class ChatBotService {
  private conversationService: ConversationService;
  private supabaseService: SupabaseService;
  private openai: OpenAI;
  private AI_MODEL = "gpt-3.5-turbo";

  constructor() {
    this.conversationService = new ConversationService();
    this.supabaseService = new SupabaseService();
    
    // Initialiser OpenAI
    this.openai = new OpenAI({
      apiKey: process.env['OPENAI_API_KEY'],
    });
  }

  /**
   * D√©marrer une nouvelle conversation avec l'IA
   */
  async startConversation(request: StartConversationRequest): Promise<{
    success: boolean;
    conversationId: string;
    expiresIn: number;
    context?: ConversationContext;
    error?: string;
  }> {
    try {
      // D√©marrer la conversation via le service local
      const result = await this.conversationService.startConversation({
        ...request,
        initialContext: request.initialContext || {}
      });

      // G√©n√©rer automatiquement une premi√®re r√©ponse IA bas√©e sur le contexte
      try {
        const firstResponseResult = await this.generateFirstResponse(result.context);
        if (firstResponseResult.response) {
          // Utiliser le messageId d'OpenAI si disponible
          const messageId = firstResponseResult.messageId;
          
          // Ajouter le message √† la conversation Redis
          await this.conversationService.addMessage(
            result.conversationId,
            {
              content: firstResponseResult.response,
              type: 'bot',
              metadata: { source: 'ai', model: this.AI_MODEL, type: 'first_response', messageId: messageId }
            }
          );
          
          // Sauvegarder le messageId d'OpenAI dans le contexte pour les r√©ponses suivantes
          if (messageId) {
            result.context.metadata = { ...result.context.metadata, previousCallId: messageId };
          }
          
          // Mettre √† jour l'entr√©e ai_response pr√©-cr√©√©e
          if (request.aiResponseId) {
            await this.supabaseService.updateAIResponse(request.aiResponseId, {
              response_text: firstResponseResult.response,
              metadata: { 
                source: 'ai', 
                model: this.AI_MODEL, 
                type: 'first_response', 
                messageId: messageId,
                status: 'completed'
              }
            });
            console.log('‚úÖ Entr√©e ai_response mise √† jour avec succ√®s:', request.aiResponseId);
          } else {
            console.warn('‚ö†Ô∏è Aucun aiResponseId fourni pour la premi√®re r√©ponse');
          }
          
          // R√©cup√©rer le contexte mis √† jour avec le premier message
          const updatedContext = await this.conversationService.getContext(result.conversationId);
          if (updatedContext) {
            result.context = updatedContext;
          }
        } else {

          console.error('‚ùå Erreur lors de la g√©n√©ration de la premi√®re r√©ponse:', 'R√©ponse vide');

        }
      } catch (aiError) {
        console.error('‚ùå Erreur lors de la g√©n√©ration de la premi√®re r√©ponse:', aiError);
        // Continuer m√™me si l'IA √©choue
      }

      return {
        success: true,
        conversationId: result.conversationId,
        expiresIn: 1800, // 30 minutes par d√©faut
        context: result.context
      };

    } catch (error) {
      console.error('‚ùå Erreur dans ChatBotService.startConversation:', error);
      return {
        success: false,
        conversationId: '',
        expiresIn: 0,
        error: 'Erreur interne du service'
      };
    }
  }

  /**
   * Ajouter un message et obtenir la r√©ponse de l'IA
   */
  async addMessage(
    conversationId: string,
    request: AddMessageRequest
  ): Promise<{
    success: boolean;
    messageId: string;
    context?: ConversationContext;
    error?: string;
  }> {
    try {
      // Ajouter le message utilisateur
      const addResult = await this.conversationService.addMessage(
        conversationId,
        {
          content: request.content,
          type: request.type,
          metadata: request.metadata || {}
        }
      );

      // Si c'est un message utilisateur, appeler l'IA pour obtenir une r√©ponse
      if (request.type === 'user') {
        try {
          // R√©cup√©rer le contexte de la conversation
          const context = await this.conversationService.getContext(conversationId);
          if (context) {
            // G√©n√©rer une r√©ponse IA
            const aiResponse = await this.generateAIResponse(context, request.content);
            
            if (aiResponse) {
               // Cr√©er un messageId unique pour la r√©ponse IA
               const messageId = `msg_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
               
              // Ajouter le message √† la conversation Redis
              await this.conversationService.addMessage(
                conversationId,
                {
                  content: aiResponse,
                  type: 'bot',
                   metadata: { source: 'ai', model: this.AI_MODEL, messageId: messageId }
                }
              );
               
               // Mettre √† jour le contexte avec le nouveau messageId
               context.metadata = { ...context.metadata, previousCallId: messageId };
              
              // Mettre √† jour l'entr√©e ai_response pr√©-cr√©√©e
              if (request.aiResponseId) {
                await this.supabaseService.updateAIResponse(request.aiResponseId, {
                  response_text: aiResponse,
                  metadata: { 
                    source: 'ai', 
                    model: this.AI_MODEL, 
                    messageId: messageId,
                    status: 'completed'
                  }
                });
                console.log('‚úÖ Entr√©e ai_response mise √† jour avec succ√®s:', request.aiResponseId);
              } else {
                console.warn('‚ö†Ô∏è Aucun aiResponseId fourni pour la r√©ponse IA');
              }
            }
          }
        } catch (aiError) {
          console.error('‚ùå Erreur lors de l\'appel IA:', aiError);
          // Continuer m√™me si l'IA √©choue
        }
      }

      // R√©cup√©rer le contexte mis √† jour
      const context = await this.conversationService.getContext(conversationId);
      
      return {
        success: true,
        messageId: addResult.messageId,
        ...(context && { context })
      };

    } catch (error) {
      console.error('‚ùå Erreur dans ChatBotService.addMessage:', error);
      return {
        success: false,
        messageId: '',
        error: 'Erreur interne du service'
      };
    }
  }

  /**
   * R√©cup√©rer le contexte d'une conversation
   */
  async getContext(conversationId: string): Promise<{
    success: boolean;
    context?: ConversationContext;
    error?: string;
  }> {
    try {
      const context = await this.conversationService.getContext(conversationId);
      if (!context) {
        return {
          success: false,
          error: 'Conversation not found'
        };
      }
      
      return {
        success: true,
        context
      };
    } catch (error) {
      console.error('‚ùå Erreur dans ChatBotService.getContext:', error);
      return {
        success: false,
        error: 'Erreur interne du service'
      };
    }
  }

  /**
   * Terminer une conversation et g√©n√©rer un r√©sum√©
   */
  async endConversation(conversationId: string, aiResponseId?: string): Promise<{
    success: boolean;
    summary?: any;
    error?: string;
  }> {
    try {
      // R√©cup√©rer le contexte final
      const context = await this.conversationService.getContext(conversationId);
      if (!context) {
        return {
          success: false,
          error: 'Impossible de r√©cup√©rer le contexte de la conversation'
        };
      }

      // G√©n√©rer un r√©sum√© IA
      const summary = await this.generateConversationSummary(context);
      
      // Terminer la conversation
      const endResult = await this.conversationService.endConversation(conversationId);
      
      return {
        success: true,
        summary: {
          ...endResult,
          aiSummary: summary
        }
      };

    } catch (error) {
      console.error('‚ùå Erreur dans ChatBotService.endConversation:', error);
      return {
        success: false,
        error: 'Erreur interne du service'
      };
    }
  }

  /**
   * G√©n√©rer une r√©ponse IA bas√©e sur le contexte de la conversation
   */
  private async generateAIResponse(context: ConversationContext, userMessage: string): Promise<string> {
    try {
      console.log('üîç G√©n√©ration d\'une nouvelle r√©ponse IA pour la conversation:', context.id);
      console.log('Dernier message de l\'utilisateur:', userMessage);

      // V√©rifier s'il y a un callID dans le contexte pour r√©f√©rencer l'appel pr√©c√©dent
      const previousCallId = context.metadata?.['previousCallId'];
      
      if (previousCallId) {
        // Utiliser l'API responses pour r√©f√©rencer l'appel pr√©c√©dent
        console.log('üîç Utilisation de l\'API responses avec callID:', previousCallId);
        
        try {
          const result = await this.openai.responses.create({
            model: this.AI_MODEL,
            input: [
              {
                role: "user",
                content: [{ type: "input_text", text: userMessage }],
              },
              {
                type: "message",
                role: "assistant",
                content: [{ 
                  type: "output_text", 
                  text: "R√©ponse pr√©c√©dente",
                  annotations: []
                }],
                id: previousCallId,
                status: "completed",
              },
            ],
          });

          const resultText = result.output
            .filter((output) => output.type === "message")
            .map((output) => (output as any).content?.[0]?.text)[0];

          console.log('üîç R√©ponse IA via API responses:', resultText);
          return resultText || "Je n'ai pas pu g√©n√©rer de r√©ponse. Pouvez-vous reformuler votre question ?";
        } catch (responseError) {
          console.warn('‚ö†Ô∏è Erreur avec l\'API responses, fallback vers chat classique:', responseError);
          // Fallback vers l'API chat classique
        }
      }

      // Utiliser l'API chat classique (premi√®re r√©ponse ou fallback)
      console.log('üîç Utilisation de l\'API chat classique');
      
      const systemPrompt = this.buildSystemPrompt(context);
      const messages = [
        { role: "system" as const, content: systemPrompt },
        { role: "user" as const, content: userMessage }
      ];

      const completion = await this.openai.chat.completions.create({
        model: this.AI_MODEL,
        messages,
        max_tokens: 500,
        temperature: 0.7
      });

      const response = completion.choices[0]?.message?.content || "Je n'ai pas pu g√©n√©rer de r√©ponse.";
      
      // Sauvegarder le callID pour les prochaines r√©ponses
      if (completion.id) {
        // Pour l'API responses, on a besoin de l'ID du message, pas de l'ID de la completion
        // On va cr√©er un identifiant unique pour ce message
        const messageId = `msg_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
        context.metadata = { ...context.metadata, previousCallId: messageId };
        
        // Mettre √† jour le contexte dans Redis en ajoutant un message
        await this.conversationService.addMessage(context.id, {
          content: response,
          type: 'bot',
          metadata: { source: 'ai', model: this.AI_MODEL, callId: completion.id, messageId: messageId }
        });
      }

      console.log('üîç R√©ponse IA classique:', response);
      return response;
    } catch (error) {
      console.error('‚ùå Erreur lors de la g√©n√©ration de la r√©ponse IA:', error);
      return "Je rencontre des difficult√©s techniques. Pouvez-vous r√©essayer dans un moment ?";
    }
  }

  /**
   * G√©n√©rer un r√©sum√© structur√© de la conversation pour les activit√©s
   */
  private async generateConversationSummary(context: ConversationContext): Promise<any> {
    try {
      // V√©rifier s'il y a un callID dans le contexte pour r√©f√©rencer l'appel pr√©c√©dent
      const previousCallId = context.metadata?.['previousCallId'];
      
      if (previousCallId && context.type === 'activity') {
        // Utiliser l'API responses pour r√©f√©rencer l'appel pr√©c√©dent
        console.log('üîç G√©n√©ration du r√©sum√© via API responses avec callID:', previousCallId);
        
        try {
          const systemPrompt = `Tu es un assistant sp√©cialis√© dans l'analyse de conversations entre praticiens et experts. 
          Analyse la conversation et g√©n√®re un r√©sum√© structur√© qui permettra de remplir automatiquement les formulaires d'activit√©.
          
          Tu dois extraire et structurer les informations suivantes :
          - shortDescription: Description courte et accrocheuse (max 200 caract√®res)
          - longDescription: Description d√©taill√©e du d√©roulement et de l'approche (max 500 caract√®res)  
          - title: Titre optimis√© et descriptif (max 100 caract√®res)
          - selectedKeywords: Mots-cl√©s pertinents parmi la liste disponible
          - benefits: B√©n√©fices concrets et mesurables pour les participants
          - typicalSituations: Profil id√©al de l'utilisateur qui profiterait de cette pratique
          
          R√©ponds UNIQUEMENT au format JSON valide selon le sch√©ma fourni.`;

          const conversationText = context.messages
            .map(msg => `${msg.type === 'user' ? 'Utilisateur' : 'Assistant'}: ${msg.content}`)
            .join('\n');

          const result = await this.openai.responses.create({
            model: this.AI_MODEL,
            input: [
              {
                role: "user",
                content: [{ type: "input_text", text: `Analyse cette conversation et g√©n√®re un r√©sum√© structur√©:\n${conversationText}` }],
              },
              {
                type: "message",
                role: "system",
                content: [{ 
                  type: "input_text", 
                  text: systemPrompt
                }],
                status: "completed",
              },
            ],
          });

          const resultText = result.output
            .filter((output) => output.type === "message")
            .map((output) => (output as any).content?.[0]?.text)[0];

          if (resultText) {
            try {
              const parsedSummary = JSON.parse(resultText);
              console.log('üîç R√©sum√© structur√© g√©n√©r√©:', parsedSummary);
              return parsedSummary;
            } catch (parseError) {
              console.warn('‚ö†Ô∏è Erreur de parsing JSON, fallback vers r√©sum√© simple:', parseError);
            }
          }
        } catch (responseError) {
          console.warn('‚ö†Ô∏è Erreur avec l\'API responses, fallback vers chat classique:', responseError);
        }
      }

      // Fallback vers l'API chat classique
      console.log('üîç G√©n√©ration du r√©sum√© via API chat classique');
      
      if (context.type === 'activity') {
        // Pour les activit√©s, g√©n√©rer un r√©sum√© structur√©
        const systemPrompt = `Tu es un assistant sp√©cialis√© dans l'analyse de conversations entre praticiens et experts. 
        Analyse la conversation et g√©n√®re un r√©sum√© structur√© qui permettra de remplir automatiquement les formulaires d'activit√©.
        
        Tu dois extraire et structurer les informations suivantes :
        - shortDescription: Description courte et accrocheuse (max 200 caract√®res)
        - longDescription: Description d√©taill√©e du d√©roulement et de l'approche (max 500 caract√®res)  
        - title: Titre optimis√© et descriptif (max 100 caract√®res)
        - selectedKeywords: Mots-cl√©s pertinents parmi la liste disponible
        - benefits: B√©n√©fices concrets et mesurables pour les participants
        - typicalSituations: Profil id√©al de l'utilisateur qui profiterait de cette pratique
        
        R√©ponds UNIQUEMENT au format JSON valide selon le sch√©ma fourni.`;

        const conversationText = context.messages
          .map(msg => `${msg.type === 'user' ? 'Utilisateur' : 'Assistant'}: ${msg.content}`)
          .join('\n');

        const completion = await this.openai.chat.completions.create({
          model: this.AI_MODEL,
          messages: [
            { role: "system", content: systemPrompt },
            { role: "user", content: `Analyse cette conversation et g√©n√®re un r√©sum√© structur√©:\n${conversationText}` }
          ],
          max_tokens: 800,
          temperature: 0.3,
          response_format: { type: "json_object" }
        });

        const response = completion.choices[0]?.message?.content;
        if (response) {
          try {
            const parsedSummary = JSON.parse(response);
            console.log('üîç R√©sum√© structur√© g√©n√©r√© via chat classique:', parsedSummary);
            return parsedSummary;
          } catch (parseError) {
            console.warn('‚ö†Ô∏è Erreur de parsing JSON, fallback vers r√©sum√© simple:', parseError);
          }
        }
      }

      // R√©sum√© simple pour les autres types ou en cas d'erreur
      const systemPrompt = `Tu es un assistant sp√©cialis√© dans la cr√©ation de r√©sum√©s concis et utiles de conversations. 
      Analyse la conversation et fournis un r√©sum√© en 2-3 phrases maximum, en fran√ßais.`;

      const conversationText = context.messages
        .map(msg => `${msg.type === 'user' ? 'Utilisateur' : 'Assistant'}: ${msg.content}`)
        .join('\n');

      const completion = await this.openai.chat.completions.create({
        model: this.AI_MODEL,
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: `R√©sume cette conversation:\n${conversationText}` }
        ],
        max_tokens: 200,
        temperature: 0.3
      });

      return {
        summary: completion.choices[0]?.message?.content || "R√©sum√© de la conversation g√©n√©r√© automatiquement."
      };
    } catch (error) {
      console.error('‚ùå Erreur lors de la g√©n√©ration du r√©sum√©:', error);
      return {
        summary: "R√©sum√© de la conversation g√©n√©r√© automatiquement."
      };
    }
  }

  /**
   * G√©n√©rer une premi√®re r√©ponse IA bas√©e sur le contexte de la conversation
   */
  private async generateFirstResponse(context: ConversationContext): Promise<{ response: string; messageId: string | undefined }> {
    try {

      console.log('üîç G√©n√©ration de la premi√®re r√©ponse IA pour la conversation:', context.id);

      const systemPrompt = this.buildSystemPrompt(context);
      
      let userPrompt = "Salue l'utilisateur et pr√©sente-toi bri√®vement en tant qu'assistant Howana.";
      
      // Personnaliser le prompt selon le type de conversation et les donn√©es disponibles
      if (context.type === 'activity' && context.activityData) {
        userPrompt = `Salue le praticien et pr√©sente-toi en tant qu'assistant Howana sp√©cialis√© dans l'accompagnement des praticiens experts.
        
        Fais un petit √©tat des lieux r√©sum√© de ce qui a √©t√© d√©clar√© :
        - Activit√© : "${context.activityData.title}"
        ${context.activityData.shortDescription ? `- Description : ${context.activityData.shortDescription}` : ''}
        
        Indique que tu es l√† pour l'aider √† compl√©ter et optimiser sa d√©claration d'activit√©.
        
        Commence par un accueil chaleureux et pose une premi√®re question engageante pour mieux comprendre son activit√© et commencer √† √©tablir la conformit√© avec sa pratique associ√©e.`;
      } else if (context.type === 'bilan') {
        userPrompt = `Salue le praticien et pr√©sente-toi en tant qu'assistant Howana sp√©cialis√© dans l'accompagnement des praticiens experts.
        
        Indique que tu es l√† pour l'aider √† faire un bilan approfondi de son activit√© ou de sa pratique.
        
        Commence par un accueil chaleureux et pose une premi√®re question engageante pour l'accompagner dans cette r√©flexion.`;
      }

      console.log('üîç System prompt:', systemPrompt);
      console.log('üîç G√©n√©ration de la premi√®re r√©ponse IA:', userPrompt);

      // Utiliser l'API responses pour la premi√®re r√©ponse
      const result = await this.openai.responses.create({
        model: this.AI_MODEL,
        input: [
          {
            role: "user",
            content: [{ type: "input_text", text: userPrompt }],
          },
          {
            type: "message",
            role: "system",
            content: [{ 
              type: "input_text", 
              text: systemPrompt
            }],
            status: "completed",
          },
        ],
      });

      // R√©cup√©rer le messageId du premier r√©sultat de type "message"
      const messageOutput = result.output.find(output => output.type === "message");
      const messageId = messageOutput?.id;
      
      // Extraire le texte de la r√©ponse en g√©rant les types
      let response = "Bonjour ! Je suis Howana, votre assistant personnel sp√©cialis√© dans le bien-√™tre. Comment puis-je vous aider aujourd'hui ?";
      if (messageOutput?.content?.[0]) {
        const content = messageOutput.content[0];
        if ('text' in content) {
          response = content.text;
        }
      }

      console.log('üîç Premi√®re r√©ponse IA via API responses:', response);
      console.log('üîç MessageID OpenAI:', messageId);

      return { 
        response, 
        messageId 
      };
    } catch (error) {
      console.error('‚ùå Erreur lors de la g√©n√©ration de la premi√®re r√©ponse:', error);
      return { 
        response: "Bonjour ! Je suis Howana, votre assistant personnel. Comment puis-je vous aider aujourd'hui ?",
        messageId: undefined
      };
    }
  }

  /**
   * Construire le prompt syst√®me bas√© sur le contexte
   */
  private buildSystemPrompt(context: ConversationContext): string {
    let basePrompt = `Tu es Howana, un assistant personnel sp√©cialis√© dans le bien-√™tre et les activit√©s de sant√©. 
    Tu es bienveillant et professionnel.`;

    // R√®gles de comportement et d'information sp√©cifiques √† respecter
    basePrompt += `\n\nR√®gles de comportement et d'information sp√©cifiques √† respecter :`;

    if (context.aiRules && Array.isArray(context.aiRules) && context.aiRules.length > 0) {
      // Filtrer seulement les r√®gles actives
      const activeRules = context.aiRules.filter((rule: AIRule) => rule.isActive);
      
      if (activeRules.length > 0) {
        // Trier les r√®gles par priorit√© (priorit√© √©lev√©e en premier)
        const sortedRules = activeRules.sort((a: AIRule, b: AIRule) => b.priority - a.priority);
        
        sortedRules.forEach((rule: AIRule, index: number) => {
          basePrompt += `\n${index + 1}. [${rule.type.toUpperCase()}] ${rule.name}: ${rule.description}`;
        });
      }
    } else if(context.type === 'activity') {
      // COMPORTEMENT PAR D√âFAUT : Howana experte des pratiques
      basePrompt += `\n1. [EXPERTISE] Expertise des pratiques: Tu es experte des pratiques de bien-√™tre et de sant√©. 
      Ton objectif est d'aider √† valider la coh√©rence entre l'activit√© et la pratique qui lui est associ√©e.`;
    } else /* bilan */ {
       // COMPORTEMENT PAR D√âFAUT : Howana analyste du mood et de l'√©tat du jour
       basePrompt += `\n1. [ANALYSE] Analyse du mood et de l'√©tat du jour: Tu es sp√©cialis√©e dans l'analyse approfondie du bien-√™tre quotidien. 
       Ton objectif est d'aider l'utilisateur √† faire un bilan d√©taill√© de son √©tat du jour et de son mood, 
       en identifiant les points importants que l'analyse statique n'a pas vus.`;
     }

    // Ajouter le contexte de l'activit√© et de la pratique si disponible
    if (context.type === 'activity' && context.activityData) {
      basePrompt += `\n\nINFORMATIONS DE L'ACTIVIT√â (d√©clar√©es par le praticien):
      - Titre: "${context.activityData.title}"`;
      
      if (context.activityData.shortDescription) {
        basePrompt += `\n- Description courte: ${context.activityData.shortDescription}`;
      }
      if (context.activityData.longDescription) {
        basePrompt += `\n- Description d√©taill√©e: ${context.activityData.longDescription}`;
      }

      // Int√©grer les informations de la pratique si disponibles
      if (context.activityData.practice) {
        const practice = context.activityData.practice;
        basePrompt += `\n\nPRATIQUE ASSOCI√âE (r√©f√©rentiel certifi√©):
        - Nom: ${practice.title}
        - Description courte: ${practice.shortDescription || 'Non disponible'}
        - Description d√©taill√©e: ${practice.longDescription || 'Non disponible'}`;
      }
      
    } else if (context.type === 'bilan') {

       if (context.aiRules && Array.isArray(context.aiRules) && context.aiRules.length > 0) {
         basePrompt += `\n\nL'utilisateur fait un bilan de son √©tat du jour et de son mood. Utilise ces informations pour appliquer tes r√®gles personnalis√©es.`;
       } else {
         basePrompt += `\n\nL'utilisateur fait un bilan de son √©tat du jour et de son mood. 
         Aide-le √† approfondir son analyse pour identifier les points importants que l'analyse statique n'a pas vus.`;
       }
    
    }

    // R√®gles g√©n√©rales (toujours pr√©sentes)
    basePrompt += `\n\nR√®gles importantes:
    - R√©ponds toujours en fran√ßais
    - Sois concis mais utile
    - Reste professionnel et bienveillant
    - Si tu ne sais pas quelque chose, dis-le honn√™tement
    - L'√©change doit contenir environ 10 questions maximum
    - Chaque r√©ponse doit TOUJOURS contenir une question pertinente`;
    
    // R√®gles contextuelles sp√©cifiques (uniquement si pas d'aiRules)
    if (!context.aiRules || !Array.isArray(context.aiRules) || context.aiRules.length === 0) {
      if (context.type === 'activity') {
        basePrompt += `
    - Ton objectif principal est d'aider le praticien √† valider la conformit√© de son activit√© avec la pratique associ√©e
    - Pose des questions pertinentes pour mieux comprendre l'activit√© et √©tablir la conformit√©
    - Identifie le profil d'utilisateur id√©al pour cette activit√©/pratique
    - Sugg√®re des ajustements si n√©cessaire pour optimiser la synergie
    - IMPORTANT: L'√©change doit se limiter √† environ 10 questions maximum
    - Chaque r√©ponse doit imp√©rativement contenir une question pour maintenir l'engagement`;
             } else if (context.type === 'bilan') {
         basePrompt += `
     - Aide l'utilisateur √† faire un bilan approfondi de son √©tat du jour et de son mood
     - Identifie les points importants que l'analyse statique n'a pas vus
     - Approfondis pour comprendre les nuances et les d√©tails significatifs
     - IMPORTANT: L'√©change doit se limiter √† environ 10 questions maximum
     - Chaque r√©ponse doit imp√©rativement contenir une question pour maintenir l'engagement`;
       }
    }

    return basePrompt;
  }

  /**
   * Changer le mod√®le IA utilis√© (pour la configuration dynamique)
   */
  setAIModel(model: string): void {
    this.AI_MODEL = model;
    console.log(`ü§ñ Mod√®le IA chang√© vers: ${model}`);
  }

  /**
   * Obtenir le mod√®le IA actuellement utilis√©
   */
  getAIModel(): string {
    return this.AI_MODEL;
  }
}
