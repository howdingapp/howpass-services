import { ConversationService } from './ConversationService';
import { SupabaseService } from './SupabaseService';
import { ConversationContext, StartConversationRequest, AddMessageRequest, AIRule } from '../types/conversation';
import OpenAI from 'openai';

export class ChatBotService {
  private conversationService: ConversationService;
  private supabaseService: SupabaseService;
  private openai: OpenAI;
  private AI_MODEL = "gpt-3.5-turbo";

  constructor() {
    this.conversationService = new ConversationService();
    this.supabaseService = new SupabaseService();
    
    // Initialiser OpenAI
    this.openai = new OpenAI({
      apiKey: process.env['OPENAI_API_KEY'],
    });
  }

  /**
   * D√©marrer une nouvelle conversation avec l'IA
   */
  async startConversation(request: StartConversationRequest): Promise<{
    success: boolean;
    conversationId: string;
    expiresIn: number;
    context?: ConversationContext;
    error?: string;
  }> {
    try {
      // D√©marrer la conversation via le service local
      const result = await this.conversationService.startConversation({
        ...request,
        initialContext: request.initialContext || {}
      });

      // G√©n√©rer automatiquement une premi√®re r√©ponse IA bas√©e sur le contexte
      try {
        const firstResponseResult = await this.generateFirstResponse(result.context);
        if (firstResponseResult.response) {
          // Utiliser le messageId d'OpenAI si disponible
          const messageId = firstResponseResult.messageId;
          
          // Ajouter le message √† la conversation Redis
          await this.conversationService.addMessage(
            result.conversationId,
            {
              content: firstResponseResult.response,
              type: 'bot',
              metadata: { source: 'ai', model: this.AI_MODEL, type: 'first_response', messageId: messageId }
            }
          );
          
          // Sauvegarder le messageId d'OpenAI dans le contexte pour les r√©ponses suivantes
          if (messageId) {
            result.context.metadata = { ...result.context.metadata, previousCallId: messageId };
          }
          
          // Enregistrer la r√©ponse IA dans Supabase
          await this.supabaseService.createAIResponse({
            conversation_id: result.conversationId,
            user_id: request.userId,
            response_text: firstResponseResult.response,
            message_type: 'text'
          });
          
          // R√©cup√©rer le contexte mis √† jour avec le premier message
          const updatedContext = await this.conversationService.getContext(result.conversationId);
          if (updatedContext) {
            result.context = updatedContext;
          }
        } else {

          console.error('‚ùå Erreur lors de la g√©n√©ration de la premi√®re r√©ponse:', 'R√©ponse vide');

        }
      } catch (aiError) {
        console.error('‚ùå Erreur lors de la g√©n√©ration de la premi√®re r√©ponse:', aiError);
        // Continuer m√™me si l'IA √©choue
      }

      return {
        success: true,
        conversationId: result.conversationId,
        expiresIn: 1800, // 30 minutes par d√©faut
        context: result.context
      };

    } catch (error) {
      console.error('‚ùå Erreur dans ChatBotService.startConversation:', error);
      return {
        success: false,
        conversationId: '',
        expiresIn: 0,
        error: 'Erreur interne du service'
      };
    }
  }

  /**
   * Ajouter un message et obtenir la r√©ponse de l'IA
   */
  async addMessage(
    conversationId: string,
    request: AddMessageRequest
  ): Promise<{
    success: boolean;
    messageId: string;
    context?: ConversationContext;
    error?: string;
  }> {
    try {
      // Ajouter le message utilisateur
      const addResult = await this.conversationService.addMessage(
        conversationId,
        {
          content: request.content,
          type: request.type,
          metadata: request.metadata || {}
        }
      );

      // Si c'est un message utilisateur, appeler l'IA pour obtenir une r√©ponse
      if (request.type === 'user') {
        try {
          // R√©cup√©rer le contexte de la conversation
          const context = await this.conversationService.getContext(conversationId);
          if (context) {
            // G√©n√©rer une r√©ponse IA
            const aiResponse = await this.generateAIResponse(context, request.content);
            
                         if (aiResponse) {
               // Cr√©er un messageId unique pour la r√©ponse IA
               const messageId = `msg_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
               
               // Ajouter le message √† la conversation Redis
               await this.conversationService.addMessage(
                 conversationId,
                 {
                   content: aiResponse,
                   type: 'bot',
                   metadata: { source: 'ai', model: this.AI_MODEL, messageId: messageId }
                 }
               );
               
               // Mettre √† jour le contexte avec le nouveau messageId
               context.metadata = { ...context.metadata, previousCallId: messageId };
              
              // Enregistrer la r√©ponse IA dans Supabase
              await this.supabaseService.createAIResponse({
                conversation_id: conversationId,
                user_id: context.userId,
                response_text: aiResponse,
                message_type: 'text'
              });
            }
          }
        } catch (aiError) {
          console.error('‚ùå Erreur lors de l\'appel IA:', aiError);
          // Continuer m√™me si l'IA √©choue
        }
      }

      // R√©cup√©rer le contexte mis √† jour
      const context = await this.conversationService.getContext(conversationId);
      
      return {
        success: true,
        messageId: addResult.messageId,
        ...(context && { context })
      };

    } catch (error) {
      console.error('‚ùå Erreur dans ChatBotService.addMessage:', error);
      return {
        success: false,
        messageId: '',
        error: 'Erreur interne du service'
      };
    }
  }

  /**
   * R√©cup√©rer le contexte d'une conversation
   */
  async getContext(conversationId: string): Promise<{
    success: boolean;
    context?: ConversationContext;
    error?: string;
  }> {
    try {
      const context = await this.conversationService.getContext(conversationId);
      if (!context) {
        return {
          success: false,
          error: 'Conversation not found'
        };
      }
      
      return {
        success: true,
        context
      };
    } catch (error) {
      console.error('‚ùå Erreur dans ChatBotService.getContext:', error);
      return {
        success: false,
        error: 'Erreur interne du service'
      };
    }
  }

  /**
   * Terminer une conversation et g√©n√©rer un r√©sum√©
   */
  async endConversation(conversationId: string): Promise<{
    success: boolean;
    summary?: any;
    error?: string;
  }> {
    try {
      // R√©cup√©rer le contexte final
      const context = await this.conversationService.getContext(conversationId);
      if (!context) {
        return {
          success: false,
          error: 'Impossible de r√©cup√©rer le contexte de la conversation'
        };
      }

      // G√©n√©rer un r√©sum√© IA
      const summary = await this.generateConversationSummary(context);
      
      // Terminer la conversation
      const endResult = await this.conversationService.endConversation(conversationId);
      
      return {
        success: true,
        summary: {
          ...endResult,
          aiSummary: summary
        }
      };

    } catch (error) {
      console.error('‚ùå Erreur dans ChatBotService.endConversation:', error);
      return {
        success: false,
        error: 'Erreur interne du service'
      };
    }
  }

  /**
   * G√©n√©rer une r√©ponse IA bas√©e sur le contexte de la conversation
   */
  private async generateAIResponse(context: ConversationContext, userMessage: string): Promise<string> {
    try {
      console.log('üîç G√©n√©ration d\'une nouvelle r√©ponse IA pour la conversation:', context.id);
      console.log('Dernier message de l\'utilisateur:', userMessage);

      // V√©rifier s'il y a un callID dans le contexte pour r√©f√©rencer l'appel pr√©c√©dent
      const previousCallId = context.metadata?.['previousCallId'];
      
      if (previousCallId) {
        // Utiliser l'API responses pour r√©f√©rencer l'appel pr√©c√©dent
        console.log('üîç Utilisation de l\'API responses avec callID:', previousCallId);
        
        try {
          const result = await this.openai.responses.create({
            model: this.AI_MODEL,
            input: [
              {
                role: "user",
                content: [{ type: "input_text", text: userMessage }],
              },
              {
                type: "message",
                role: "assistant",
                content: [{ 
                  type: "output_text", 
                  text: "R√©ponse pr√©c√©dente",
                  annotations: []
                }],
                id: previousCallId,
                status: "completed",
              },
            ],
          });

          const resultText = result.output
            .filter((output) => output.type === "message")
            .map((output) => (output as any).content?.[0]?.text)[0];

          console.log('üîç R√©ponse IA via API responses:', resultText);
          return resultText || "Je n'ai pas pu g√©n√©rer de r√©ponse. Pouvez-vous reformuler votre question ?";
        } catch (responseError) {
          console.warn('‚ö†Ô∏è Erreur avec l\'API responses, fallback vers chat classique:', responseError);
          // Fallback vers l'API chat classique
        }
      }

      // Utiliser l'API chat classique (premi√®re r√©ponse ou fallback)
      console.log('üîç Utilisation de l\'API chat classique');
      
      const systemPrompt = this.buildSystemPrompt(context);
      const messages = [
        { role: "system" as const, content: systemPrompt },
        { role: "user" as const, content: userMessage }
      ];

      const completion = await this.openai.chat.completions.create({
        model: this.AI_MODEL,
        messages,
        max_tokens: 500,
        temperature: 0.7
      });

      const response = completion.choices[0]?.message?.content || "Je n'ai pas pu g√©n√©rer de r√©ponse.";
      
      // Sauvegarder le callID pour les prochaines r√©ponses
      if (completion.id) {
        // Pour l'API responses, on a besoin de l'ID du message, pas de l'ID de la completion
        // On va cr√©er un identifiant unique pour ce message
        const messageId = `msg_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
        context.metadata = { ...context.metadata, previousCallId: messageId };
        
        // Mettre √† jour le contexte dans Redis en ajoutant un message
        await this.conversationService.addMessage(context.id, {
          content: response,
          type: 'bot',
          metadata: { source: 'ai', model: this.AI_MODEL, callId: completion.id, messageId: messageId }
        });
      }

      console.log('üîç R√©ponse IA classique:', response);
      return response;
    } catch (error) {
      console.error('‚ùå Erreur lors de la g√©n√©ration de la r√©ponse IA:', error);
      return "Je rencontre des difficult√©s techniques. Pouvez-vous r√©essayer dans un moment ?";
    }
  }

  /**
   * G√©n√©rer un r√©sum√© de la conversation
   */
  private async generateConversationSummary(context: ConversationContext): Promise<string> {
    try {
      const systemPrompt = `Tu es un assistant sp√©cialis√© dans la cr√©ation de r√©sum√©s concis et utiles de conversations. 
      Analyse la conversation et fournis un r√©sum√© en 2-3 phrases maximum, en fran√ßais.`;

      const conversationText = context.messages
        .map(msg => `${msg.type === 'user' ? 'Utilisateur' : 'Assistant'}: ${msg.content}`)
        .join('\n');

      const completion = await this.openai.chat.completions.create({
        model: this.AI_MODEL,
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: `R√©sume cette conversation:\n${conversationText}` }
        ],
        max_tokens: 200,
        temperature: 0.3
      });

      return completion.choices[0]?.message?.content || "R√©sum√© de la conversation g√©n√©r√© automatiquement.";
    } catch (error) {
      console.error('‚ùå Erreur lors de la g√©n√©ration du r√©sum√©:', error);
      return "R√©sum√© de la conversation g√©n√©r√© automatiquement.";
    }
  }

  /**
   * G√©n√©rer une premi√®re r√©ponse IA bas√©e sur le contexte de la conversation
   */
  private async generateFirstResponse(context: ConversationContext): Promise<{ response: string; messageId: string | undefined }> {
    try {

      console.log('üîç G√©n√©ration de la premi√®re r√©ponse IA pour la conversation:', context.id);

      const systemPrompt = this.buildSystemPrompt(context);
      
      let userPrompt = "Salue l'utilisateur et pr√©sente-toi bri√®vement en tant qu'assistant Howana.";
      
      // Personnaliser le prompt selon le type de conversation et les donn√©es disponibles
      if (context.type === 'activity' && context.activityData) {
        userPrompt = `Salue le praticien et pr√©sente-toi en tant qu'assistant Howana sp√©cialis√© dans l'accompagnement des praticiens experts. 
        Le praticien souhaite d√©clarer une activit√©: "${context.activityData.title}".
        ${context.activityData.shortDescription ? `Description courte: ${context.activityData.shortDescription}` : ''}
        Commence par un accueil chaleureux et pose une premi√®re question engageante pour mieux comprendre son activit√© et commencer √† √©tablir la conformit√© avec sa pratique associ√©e.`;
      } else if (context.type === 'bilan') {
        userPrompt = `Salue le praticien et pr√©sente-toi en tant qu'assistant Howana sp√©cialis√© dans l'accompagnement des praticiens experts. 
        Le praticien souhaite faire un bilan de son activit√© ou de sa pratique. 
        Commence par un accueil chaleureux et pose une premi√®re question engageante pour l'accompagner dans cette r√©flexion.`;
      }

      console.log('üîç System prompt:', systemPrompt);
      console.log('üîç G√©n√©ration de la premi√®re r√©ponse IA:', userPrompt);

      // Utiliser l'API responses pour la premi√®re r√©ponse
      const result = await this.openai.responses.create({
        model: this.AI_MODEL,
        input: [
          {
            role: "user",
            content: [{ type: "input_text", text: userPrompt }],
          },
          {
            type: "message",
            role: "system",
            content: [{ 
              type: "input_text", 
              text: systemPrompt
            }],
            status: "completed",
          },
        ],
      });

      // R√©cup√©rer le messageId du premier r√©sultat de type "message"
      const messageOutput = result.output.find(output => output.type === "message");
      const messageId = messageOutput?.id;
      
      // Extraire le texte de la r√©ponse en g√©rant les types
      let response = "Bonjour ! Je suis Howana, votre assistant personnel sp√©cialis√© dans le bien-√™tre. Comment puis-je vous aider aujourd'hui ?";
      if (messageOutput?.content?.[0]) {
        const content = messageOutput.content[0];
        if ('text' in content) {
          response = content.text;
        }
      }

      console.log('üîç Premi√®re r√©ponse IA via API responses:', response);
      console.log('üîç MessageID OpenAI:', messageId);

      return { 
        response, 
        messageId 
      };
    } catch (error) {
      console.error('‚ùå Erreur lors de la g√©n√©ration de la premi√®re r√©ponse:', error);
      return { 
        response: "Bonjour ! Je suis Howana, votre assistant personnel. Comment puis-je vous aider aujourd'hui ?",
        messageId: undefined
      };
    }
  }

  /**
   * Construire le prompt syst√®me bas√© sur le contexte
   */
  private buildSystemPrompt(context: ConversationContext): string {
    let basePrompt = `Tu es Howana, un assistant personnel sp√©cialis√© dans le bien-√™tre et les activit√©s de sant√©. 
    Tu es bienveillant, professionnel et tu aides les utilisateurs √† am√©liorer leur qualit√© de vie.`;

    // Si des r√®gles IA personnalis√©es sont pr√©sentes, les utiliser exclusivement
    if (context.aiRules && Array.isArray(context.aiRules) && context.aiRules.length > 0) {
      // Filtrer seulement les r√®gles actives
      const activeRules = context.aiRules.filter((rule: AIRule) => rule.isActive);
      
      if (activeRules.length > 0) {
        basePrompt += `\n\nR√®gles de comportement et d'information sp√©cifiques √† respecter :`;
        
        // Trier les r√®gles par priorit√© (priorit√© √©lev√©e en premier)
        const sortedRules = activeRules.sort((a: AIRule, b: AIRule) => b.priority - a.priority);
        
        sortedRules.forEach((rule: AIRule, index: number) => {
          basePrompt += `\n${index + 1}. [${rule.type.toUpperCase()}] ${rule.name}: ${rule.description}`;
        });
        
        // Retourner le prompt avec seulement les r√®gles personnalis√©es
        return basePrompt;
      }
    }

    // COMPORTEMENT PAR D√âFAUT : Howana experte des pratiques
    basePrompt += `\n\nTu es √©galement experte des pratiques de bien-√™tre et de sant√©. 
    Ton objectif est d'aider √† valider la coh√©rence entre l'activit√© et la pratique qui lui est associ√©e.`;

    // Ajouter le contexte de l'activit√© et de la pratique si disponible
    if (context.type === 'activity' && context.activityData) {
      basePrompt += `\n\nL'utilisateur discute d'une activit√© sp√©cifique: "${context.activityData.title}".`;
      
      if (context.activityData.shortDescription) {
        basePrompt += `\nDescription courte: ${context.activityData.shortDescription}`;
      }
      if (context.activityData.longDescription) {
        basePrompt += `\nDescription d√©taill√©e: ${context.activityData.longDescription}`;
      }

      // Int√©grer les informations de la pratique si disponibles
      if (context.activityData.practice) {
        const practice = context.activityData.practice;
        basePrompt += `\n\nPRATIQUE ASSOCI√âE:
        - Nom: ${practice.title}
        - Description courte: ${practice.shortDescription || 'Non disponible'}
        - Description d√©taill√©e: ${practice.longDescription || 'Non disponible'}
        - Cat√©gorie ID: ${practice.categoryId || 'Non d√©finie'}
        - Famille ID: ${practice.familyId || 'Non d√©finie'}`;
        
        basePrompt += `\n\nEn tant qu'experte de cette pratique, tu dois:
        1. Analyser la coh√©rence entre l'activit√© et la pratique
        2. Poser des questions intelligentes pour mieux comprendre l'activit√©
        3. Identifier le profil d'utilisateur id√©al (√©tat psychologique, v√©cu, besoins sp√©cifiques)
        4. Valider si l'activit√© respecte les principes de la pratique
        5. Sugg√©rer des ajustements si n√©cessaire pour optimiser la synergie`;
      }
      
      basePrompt += `\n\nAide l'utilisateur √† optimiser cette activit√© en te basant sur ton expertise de la pratique associ√©e.`;
      
    } else if (context.type === 'bilan') {
      basePrompt += `\n\nL'utilisateur fait un bilan de son bien-√™tre. 
      Aide-le √† analyser sa situation et propose des am√©liorations personnalis√©es.`;
    }

    basePrompt += `\n\nR√®gles importantes:
    - R√©ponds toujours en fran√ßais
    - Sois concis mais utile
    - Adapte tes conseils au contexte de l'utilisateur
    - Reste professionnel et bienveillant
    - Si tu ne sais pas quelque chose, dis-le honn√™tement
    - En mode "expertise des pratiques" par d√©faut, pose des questions pertinentes pour valider la coh√©rence
    - Identifie toujours le profil d'utilisateur id√©al pour l'activit√©/pratique
    - Sugg√®re des ajustements si n√©cessaire pour optimiser la synergie`;

    return basePrompt;
  }

  /**
   * Changer le mod√®le IA utilis√© (pour la configuration dynamique)
   */
  setAIModel(model: string): void {
    this.AI_MODEL = model;
    console.log(`ü§ñ Mod√®le IA chang√© vers: ${model}`);
  }

  /**
   * Obtenir le mod√®le IA actuellement utilis√©
   */
  getAIModel(): string {
    return this.AI_MODEL;
  }
}
