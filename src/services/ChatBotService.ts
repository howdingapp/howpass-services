import { ConversationService } from './ConversationService';
import { SupabaseService } from './SupabaseService';
import { ConversationContext, StartConversationRequest, AddMessageRequest, AIRule } from '../types/conversation';
import OpenAI from 'openai';

export class ChatBotService {
  private conversationService: ConversationService;
  private supabaseService: SupabaseService;
  private openai: OpenAI;
  private AI_MODEL = "gpt-3.5-turbo";

  constructor() {
    this.conversationService = new ConversationService();
    this.supabaseService = new SupabaseService();
    
    // Initialiser OpenAI
    this.openai = new OpenAI({
      apiKey: process.env['OPENAI_API_KEY'],
    });
  }

  /**
   * D√©marrer une nouvelle conversation avec l'IA
   */
  async startConversation(request: StartConversationRequest): Promise<{
    success: boolean;
    conversationId: string;
    expiresIn: number;
    context?: ConversationContext;
    error?: string;
  }> {
    try {
      // D√©marrer la conversation via le service local
      const result = await this.conversationService.startConversation({
        userId: request.userId,
        type: request.type,
        initialContext: request.initialContext || {}
      });

      // G√©n√©rer automatiquement une premi√®re r√©ponse IA bas√©e sur le contexte
      try {
        const firstResponse = await this.generateFirstResponse(result.context);
        if (firstResponse) {
          // Ajouter le message √† la conversation Redis
          await this.conversationService.addMessage(
            result.conversationId,
            {
              content: firstResponse,
              type: 'bot',
                             metadata: { source: 'ai', model: this.AI_MODEL, type: 'first_response' }
            }
          );
          
          // Enregistrer la r√©ponse IA dans Supabase
          await this.supabaseService.createAIResponse({
            conversation_id: result.conversationId,
            user_id: request.userId,
            response_text: firstResponse,
            message_type: 'text'
          });
          
          // R√©cup√©rer le contexte mis √† jour avec le premier message
          const updatedContext = await this.conversationService.getContext(result.conversationId);
          if (updatedContext) {
            result.context = updatedContext;
          }
        } else {

          console.error('‚ùå Erreur lors de la g√©n√©ration de la premi√®re r√©ponse:', 'R√©ponse vide');

        }
      } catch (aiError) {
        console.error('‚ùå Erreur lors de la g√©n√©ration de la premi√®re r√©ponse:', aiError);
        // Continuer m√™me si l'IA √©choue
      }

      return {
        success: true,
        conversationId: result.conversationId,
        expiresIn: 1800, // 30 minutes par d√©faut
        context: result.context
      };

    } catch (error) {
      console.error('‚ùå Erreur dans ChatBotService.startConversation:', error);
      return {
        success: false,
        conversationId: '',
        expiresIn: 0,
        error: 'Erreur interne du service'
      };
    }
  }

  /**
   * Ajouter un message et obtenir la r√©ponse de l'IA
   */
  async addMessage(
    conversationId: string,
    request: AddMessageRequest
  ): Promise<{
    success: boolean;
    messageId: string;
    context?: ConversationContext;
    error?: string;
  }> {
    try {
      // Ajouter le message utilisateur
      const addResult = await this.conversationService.addMessage(
        conversationId,
        {
          content: request.content,
          type: request.type,
          metadata: request.metadata || {}
        }
      );

      // Si c'est un message utilisateur, appeler l'IA pour obtenir une r√©ponse
      if (request.type === 'user') {
        try {
          // R√©cup√©rer le contexte de la conversation
          const context = await this.conversationService.getContext(conversationId);
          if (context) {
            // G√©n√©rer une r√©ponse IA
            const aiResponse = await this.generateAIResponse(context, request.content);
            
            if (aiResponse) {
              // Ajouter le message √† la conversation Redis
              await this.conversationService.addMessage(
                conversationId,
                {
                  content: aiResponse,
                  type: 'bot',
                  metadata: { source: 'ai', model: this.AI_MODEL }
                }
              );
              
              // Enregistrer la r√©ponse IA dans Supabase
              await this.supabaseService.createAIResponse({
                conversation_id: conversationId,
                user_id: context.userId,
                response_text: aiResponse,
                message_type: 'text'
              });
            }
          }
        } catch (aiError) {
          console.error('‚ùå Erreur lors de l\'appel IA:', aiError);
          // Continuer m√™me si l'IA √©choue
        }
      }

      // R√©cup√©rer le contexte mis √† jour
      const context = await this.conversationService.getContext(conversationId);
      
      return {
        success: true,
        messageId: addResult.messageId,
        ...(context && { context })
      };

    } catch (error) {
      console.error('‚ùå Erreur dans ChatBotService.addMessage:', error);
      return {
        success: false,
        messageId: '',
        error: 'Erreur interne du service'
      };
    }
  }

  /**
   * R√©cup√©rer le contexte d'une conversation
   */
  async getContext(conversationId: string): Promise<{
    success: boolean;
    context?: ConversationContext;
    error?: string;
  }> {
    try {
      const context = await this.conversationService.getContext(conversationId);
      if (!context) {
        return {
          success: false,
          error: 'Conversation not found'
        };
      }
      
      return {
        success: true,
        context
      };
    } catch (error) {
      console.error('‚ùå Erreur dans ChatBotService.getContext:', error);
      return {
        success: false,
        error: 'Erreur interne du service'
      };
    }
  }

  /**
   * Terminer une conversation et g√©n√©rer un r√©sum√©
   */
  async endConversation(conversationId: string): Promise<{
    success: boolean;
    summary?: any;
    error?: string;
  }> {
    try {
      // R√©cup√©rer le contexte final
      const context = await this.conversationService.getContext(conversationId);
      if (!context) {
        return {
          success: false,
          error: 'Impossible de r√©cup√©rer le contexte de la conversation'
        };
      }

      // G√©n√©rer un r√©sum√© IA
      const summary = await this.generateConversationSummary(context);
      
      // Terminer la conversation
      const endResult = await this.conversationService.endConversation(conversationId);
      
      return {
        success: true,
        summary: {
          ...endResult,
          aiSummary: summary
        }
      };

    } catch (error) {
      console.error('‚ùå Erreur dans ChatBotService.endConversation:', error);
      return {
        success: false,
        error: 'Erreur interne du service'
      };
    }
  }

  /**
   * G√©n√©rer une r√©ponse IA bas√©e sur le contexte de la conversation
   */
  private async generateAIResponse(context: ConversationContext, userMessage: string): Promise<string> {
    try {
      const systemPrompt = this.buildSystemPrompt(context);
      
      // Construire l'historique des messages
      const messages = [
        { role: "system" as const, content: systemPrompt },
        ...context.messages.map(msg => ({
          role: (msg.type === 'user' ? 'user' : 'assistant') as 'user' | 'assistant',
          content: msg.content
        })),
        { role: "user" as const, content: userMessage }
      ];

      console.log('üîç G√©n√©ration d\'une nouvelle r√©ponse IA pour la conversation:', context.id);
      console.log('Dernier message de l\'utilisateur:', userMessage);

      const completion = await this.openai.chat.completions.create({
        model: this.AI_MODEL,
        messages,
        max_tokens: 500,
        temperature: 0.7
      });

      console.log('üîç R√©ponse IA:', completion.choices[0]?.message?.content || 'Aucune r√©ponse g√©n√©r√©e');

      return completion.choices[0]?.message?.content || "Je n'ai pas pu g√©n√©rer de r√©ponse. Pouvez-vous reformuler votre question ?";
    } catch (error) {
      console.error('‚ùå Erreur lors de la g√©n√©ration de la r√©ponse IA:', error);
      return "Je rencontre des difficult√©s techniques. Pouvez-vous r√©essayer dans un moment ?";
    }
  }

  /**
   * G√©n√©rer un r√©sum√© de la conversation
   */
  private async generateConversationSummary(context: ConversationContext): Promise<string> {
    try {
      const systemPrompt = `Tu es un assistant sp√©cialis√© dans la cr√©ation de r√©sum√©s concis et utiles de conversations. 
      Analyse la conversation et fournis un r√©sum√© en 2-3 phrases maximum, en fran√ßais.`;

      const conversationText = context.messages
        .map(msg => `${msg.type === 'user' ? 'Utilisateur' : 'Assistant'}: ${msg.content}`)
        .join('\n');

      const completion = await this.openai.chat.completions.create({
        model: this.AI_MODEL,
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: `R√©sume cette conversation:\n${conversationText}` }
        ],
        max_tokens: 200,
        temperature: 0.3
      });

      return completion.choices[0]?.message?.content || "R√©sum√© de la conversation g√©n√©r√© automatiquement.";
    } catch (error) {
      console.error('‚ùå Erreur lors de la g√©n√©ration du r√©sum√©:', error);
      return "R√©sum√© de la conversation g√©n√©r√© automatiquement.";
    }
  }

  /**
   * G√©n√©rer une premi√®re r√©ponse IA bas√©e sur le contexte de la conversation
   */
  private async generateFirstResponse(context: ConversationContext): Promise<string> {
    try {

      console.log('üîç G√©n√©ration de la premi√®re r√©ponse IA pour la conversation:', context.id);

      const systemPrompt = this.buildSystemPrompt(context);
      
      let userPrompt = "Salue l'utilisateur et pr√©sente-toi bri√®vement en tant qu'assistant Howana.";
      
      // Personnaliser le prompt selon le type de conversation et les donn√©es disponibles
      if (context.type === 'activity' && context.activityData) {
        userPrompt = `Salue l'utilisateur et pr√©sente-toi en tant qu'assistant Howana sp√©cialis√© dans les activit√©s de bien-√™tre. 
        L'utilisateur souhaite discuter de l'activit√©: "${context.activityData.title}".
        ${context.activityData.description ? `Description: ${context.activityData.description}` : ''}
        Commence par un accueil chaleureux et propose de l'aider avec cette activit√©.`;
      } else if (context.type === 'bilan') {
        userPrompt = `Salue l'utilisateur et pr√©sente-toi en tant qu'assistant Howana sp√©cialis√© dans le bilan de bien-√™tre. 
        L'utilisateur souhaite faire un bilan de sa situation. 
        Commence par un accueil chaleureux et propose de l'accompagner dans cette r√©flexion.`;
      }

      console.log('üîç System prompt:', systemPrompt);
      console.log('üîç G√©n√©ration de la premi√®re r√©ponse IA:', userPrompt);

      const completion = await this.openai.chat.completions.create({
        model: this.AI_MODEL,
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: userPrompt }
        ],
        max_tokens: 200,
        temperature: 0.7
      });

      console.log('üîç Premi√®re r√©ponse IA:', completion.choices[0]?.message?.content || 'Aucune r√©ponse g√©n√©r√©e');

      return completion.choices[0]?.message?.content || "Bonjour ! Je suis Howana, votre assistant personnel sp√©cialis√© dans le bien-√™tre. Comment puis-je vous aider aujourd'hui ?";
    } catch (error) {
      console.error('‚ùå Erreur lors de la g√©n√©ration de la premi√®re r√©ponse:', error);
      return "Bonjour ! Je suis Howana, votre assistant personnel. Comment puis-je vous aider aujourd'hui ?";
    }
  }

  /**
   * Construire le prompt syst√®me bas√© sur le contexte
   */
  private buildSystemPrompt(context: ConversationContext): string {
    let basePrompt = `Tu es Howana, un assistant personnel sp√©cialis√© dans le bien-√™tre et les activit√©s de sant√©. 
    Tu es bienveillant, professionnel et tu aides les utilisateurs √† am√©liorer leur qualit√© de vie.`;

    // Ajouter les r√®gles IA sp√©cifiques si elles existent
    if (context.aiRules && Array.isArray(context.aiRules)) {
      // Filtrer seulement les r√®gles actives
      const activeRules = context.aiRules.filter((rule: AIRule) => rule.isActive);
      
      if (activeRules.length > 0) {
        basePrompt += `\n\nR√®gles de comportement et d'information sp√©cifiques √† respecter :`;
        
        // Trier les r√®gles par priorit√© (priorit√© √©lev√©e en premier)
        const sortedRules = activeRules.sort((a: AIRule, b: AIRule) => b.priority - a.priority);
        
        sortedRules.forEach((rule: AIRule, index: number) => {
          basePrompt += `\n${index + 1}. [${rule.type.toUpperCase()}] ${rule.name}: ${rule.description}`;
        });
      }
    }

    // Ajouter le contexte de l'activit√© si disponible
    if (context.type === 'activity' && context.activityData) {
      basePrompt += `\n\nL'utilisateur discute d'une activit√© sp√©cifique: "${context.activityData.title}". 
      ${context.activityData.description ? `Description: ${context.activityData.description}` : ''}
      Aide-le √† optimiser cette activit√©, r√©ponds √† ses questions et donne des conseils pratiques.`;
    } else if (context.type === 'bilan') {
      basePrompt += `\n\nL'utilisateur fait un bilan de son bien-√™tre. 
      Aide-le √† analyser sa situation et propose des am√©liorations personnalis√©es.`;
    }

    basePrompt += `\n\nR√®gles importantes:
    - R√©ponds toujours en fran√ßais
    - Sois concis mais utile
    - Adapte tes conseils au contexte de l'utilisateur
    - Reste professionnel et bienveillant
    - Si tu ne sais pas quelque chose, dis-le honn√™tement
    - Respecte strictement toutes les r√®gles de comportement et d'information sp√©cifi√©es ci-dessus`;

    return basePrompt;
  }

  /**
   * Changer le mod√®le IA utilis√© (pour la configuration dynamique)
   */
  setAIModel(model: string): void {
    this.AI_MODEL = model;
    console.log(`ü§ñ Mod√®le IA chang√© vers: ${model}`);
  }

  /**
   * Obtenir le mod√®le IA actuellement utilis√©
   */
  getAIModel(): string {
    return this.AI_MODEL;
  }
}
