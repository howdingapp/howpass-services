import { spawn } from 'child_process';
import fs from 'fs-extra';
import path from 'path';
import { v4 as uuidv4 } from 'uuid';
import { SupabaseService, VIDEO_BUCKET, SOUND_BUCKET } from './SupabaseService';

export interface MergeRequest {
  prefixVideo1BucketPath: string; // Premi√®re vid√©o pr√©fixe (qr_code_scene1_part1.mp4)
  prefixVideo2BucketPath: string; // Deuxi√®me vid√©o pr√©fixe (qr_code_scene1_part2.mp4)
  postfixVideoUrl: string; // Vid√©o fournie par le webhook
  audioBucketPath?: string; // Son optionnel (ytmp3free.cc_playa-blanca-dream-youtubemp3free.org.mp3)
  quality?: 'low' | 'medium' | 'high';
  resolution?: string;
  fps?: number;
  audioCodec?: string;
  videoCodec?: string;
  metadata?: {
    table?: string;
    recordId?: string | number;
    operation?: string;
    [key: string]: any;
  };
}

export interface MergeResponse {
  success: boolean;
  outputUrl?: string;
  error?: string;
  jobId: string;
}

export interface JobStatus {
  id: string;
  status: 'pending' | 'processing' | 'completed' | 'failed';
  progress?: number;
  outputUrl?: string;
  error?: string;
  createdAt: Date;
  updatedAt: Date;
}

export interface FFmpegOptions {
  prefixVideo1Path: string; // Chemin vers la premi√®re vid√©o pr√©fixe
  prefixVideo2Path: string; // Chemin vers la deuxi√®me vid√©o pr√©fixe
  postfixPath: string; // Chemin vers la vid√©o postfixe
  audioPath?: string; // Chemin vers le fichier audio
  outputPath: string;
  quality?: string | undefined;
  resolution?: string | undefined;
  fps?: number | undefined;
  audioCodec?: string | undefined;
  videoCodec?: string | undefined;
  threads?: number;
  timeout?: number;
  prefix1Duration?: number; // Dur√©e du prefix1 pour synchroniser l'audio
  metadata?: {
    table?: string;
    recordId?: string | number;
    operation?: string;
    [key: string]: any;
  };
}

export interface VideoInfo {
  duration: number;
  width: number;
  height: number;
  fps: number;
  bitrate: number;
  audioCodec?: string;
  videoCodec?: string;
  format: string;
}

export class VideoService {
  private tempPath: string;
  private jobs: Map<string, JobStatus> = new Map();
  private supabaseService: SupabaseService;

  constructor() {
    this.tempPath = process.env['TEMP_PATH'] || './temp';
    this.supabaseService = new SupabaseService();
    
    // Cr√©er les r√©pertoires s'ils n'existent pas
    this.ensureDirectories();
  }

  private ensureDirectories(): void {
    fs.ensureDirSync(this.tempPath);
  }

  async getVideoInfo(filePath: string): Promise<VideoInfo> {
    return new Promise((resolve, reject) => {
      const ffmpeg = spawn('ffprobe', [
        '-v', 'quiet',
        '-print_format', 'json',
        '-show_format',
        '-show_streams',
        filePath
      ]);
      
      let output = '';
      let errorOutput = '';
      
      ffmpeg.stdout.on('data', (data) => {
        output += data.toString();
      });
      
      ffmpeg.stderr.on('data', (data) => {
        errorOutput += data.toString();
      });
      
      ffmpeg.on('close', (code) => {
        if (code !== 0) {
          console.error(`ffprobe error code: ${code}`);
          console.error(`ffprobe stderr: ${errorOutput}`);
          reject(new Error(`ffprobe error code: ${code}`));
          return;
        }
        
        try {
          const metadata = JSON.parse(output);
          const videoStream = metadata.streams.find((stream: any) => stream.codec_type === 'video');
          const audioStream = metadata.streams.find((stream: any) => stream.codec_type === 'audio');

          if (!videoStream) {
            reject(new Error('Aucun flux vid√©o trouv√©'));
            return;
          }

          resolve({
            duration: parseFloat(metadata.format.duration) || 0,
            width: videoStream.width || 0,
            height: videoStream.height || 0,
            fps: this.parseFPS(videoStream.r_frame_rate || '0/1'),
            bitrate: metadata.format.bit_rate ? parseInt(metadata.format.bit_rate) : 0,
            audioCodec: audioStream?.codec_name,
            videoCodec: videoStream.codec_name,
            format: metadata.format.format_name || 'unknown'
          });
        } catch (error) {
          reject(new Error(`Erreur lors de l'analyse de la vid√©o: ${error instanceof Error ? error.message : 'Erreur inconnue'}`));
        }
      });
      
      ffmpeg.on('error', (err) => {
        console.error('‚ùå Erreur ffprobe:', err);
        reject(new Error(`Erreur ffprobe: ${err.message}`));
      });
    });
  }

  private parseFPS(fpsString: string): number {
    const parts = fpsString.split('/');
    const num = parts[0] ? parseInt(parts[0]) : 0;
    const den = parts[1] ? parseInt(parts[1]) : 1;
    return den ? num / den : 0;
  }

  async mergeVideos(request: MergeRequest): Promise<MergeResponse> {
    const jobId = uuidv4();
    
    // Cr√©er le job
    const job: JobStatus = {
      id: jobId,
      status: 'pending',
      progress: 0,
      createdAt: new Date(),
      updatedAt: new Date()
    };
    
    this.jobs.set(jobId, job);

    try {
      console.log(`üé¨ D√©but du job de fusion ${jobId}`);
      console.log(`üìπ Prefix Video 1: ${request.prefixVideo1BucketPath}`);
      console.log(`üìπ Prefix Video 2: ${request.prefixVideo2BucketPath}`);
      console.log(`üìπ Postfix: ${request.postfixVideoUrl}`);
      if (request.audioBucketPath) {
        console.log(`üéµ Audio: ${request.audioBucketPath}`);
      }

      // Traiter les champs de pr√©sentation
      console.log('üé¨ Traitement des champs de pr√©sentation');
      return await this.processVideoFields(request, jobId);
    } catch (error) {
      console.error('‚ùå Erreur lors du traitement vid√©o:', error);
      return {
        success: false,
        error: error instanceof Error ? error.message : 'Erreur inconnue',
        jobId
      };
    }
  }

  private executeTwoStepMerge(options: FFmpegOptions, jobId: string): Promise<void> {
    return new Promise(async (resolve, reject) => {
      try {
        console.log('üé¨ D√©but de la fusion en deux √©tapes...');

        // √âtape 1 : Cr√©er prefix2+postfix+audio
        const intermediatePath = path.join(this.tempPath, `intermediate_${jobId}.mp4`);
        
        console.log('üìπ √âtape 1 : Cr√©ation de prefix2+postfix+audio...');
        await this.createIntermediateVideo(options.prefixVideo2Path, options.postfixPath, options.audioPath!, intermediatePath, options);

        // Sauvegarder la vid√©o interm√©diaire dans le bucket
        const table = options.metadata?.table || 'practices';
        const recordId = options.metadata?.recordId || jobId;
        const midDateSuffix = new Date().toISOString().slice(0, 10).replace(/-/g, ''); // Format: YYYYMMDD
        const midDestinationPath = `${table}/${recordId}_mid_${midDateSuffix}.mp4`;
        
        console.log('üì§ Upload de la vid√©o interm√©diaire vers Supabase:', { midDestinationPath });
        const midVideoOutputUrl = await this.supabaseService.upload(VIDEO_BUCKET, intermediatePath, midDestinationPath);
        
        // Mettre √† jour le champ qr_code_less_presentation_video_public_url dans Supabase
        await this.supabaseService.updateQrCodePresentationVideoMidUrl(table, recordId, midVideoOutputUrl);
        console.log('‚úÖ Vid√©o interm√©diaire sauvegard√©e et associ√©e dans Supabase');

        // √âtape 2 : Concat√©ner prefix1 + vid√©o interm√©diaire
        console.log('üìπ √âtape 2 : Concat√©nation prefix1 + vid√©o interm√©diaire...');
        await this.concatWithPrefix1(options.prefixVideo1Path, intermediatePath, options.outputPath, options);

        // Upload de la vid√©o finale vers Supabase
        console.log('üì§ Upload de la vid√©o finale...');
        const finalDateSuffix = new Date().toISOString().slice(0, 10).replace(/-/g, ''); // Format: YYYYMMDD
        const destinationPath = `${table}/${recordId}_merged_${finalDateSuffix}.mp4`;
        const mergedVideoOutputUrl = await this.supabaseService.upload(VIDEO_BUCKET, options.outputPath, destinationPath);

        // Mettre √† jour le champ qr_code_presentation_video_public_url dans la base de donn√©es
        console.log('üìù Mise √† jour du champ qr_code_presentation_video_public_url...');
        const updateSuccess = await this.supabaseService.updateQrCodePresentationVideoUrl(table, recordId, mergedVideoOutputUrl);
        
        if (!updateSuccess) {
          console.error('‚ùå √âchec de la mise √† jour du champ qr_code_presentation_video_public_url pour:', { table, recordId });
          throw new Error('√âchec de la mise √† jour de la base de donn√©es');
        }

        console.log('‚úÖ Champ qr_code_presentation_video_public_url mis √† jour avec succ√®s');
        console.log('‚úÖ Fusion en deux √©tapes termin√©e avec succ√®s');
        resolve();
      } catch (error) {
        console.error('‚ùå Erreur lors de la fusion en deux √©tapes:', error);
        reject(error);
      }
    });
  }

  private createIntermediateVideo(prefix2Path: string, postfixPath: string, audioPath: string, outputPath: string, options: FFmpegOptions): Promise<void> {
    return new Promise((resolve, reject) => {
      console.log('üé¨ Cr√©ation de la vid√©o interm√©diaire...');

      const args = [
        '-i', prefix2Path,        // vid√©o 1
        '-i', postfixPath,        // vid√©o 2
        '-i', audioPath,          // musique
        '-filter_complex',
          '[0:v][1:v]concat=n=2:v=1:a=0[concatv];' +
          '[2:a]atrim=duration=30,asetpts=PTS-STARTPTS[trima]',
        '-map', '[concatv]',
        '-map', '[trima]',
        '-c:v', 'libx264',
        '-c:a', 'aac',
        '-r', (options.fps || 25).toString(),
        '-crf', options.quality === 'low' ? '28' : options.quality === 'medium' ? '23' : '18',
        '-threads', (options.threads || 4).toString(),
        '-t', '30', // ‚Üê force dur√©e finale √† 30s
        '-y',
        outputPath
      ];


      console.log('üé¨ Arguments FFmpeg (interm√©diaire):', args.join(' '));

      const ffmpeg = spawn('ffmpeg', args);

      let stderr = '';

      ffmpeg.stderr.on('data', (data) => {
        stderr += data.toString();
        console.log(`üé¨ FFmpeg (interm√©diaire): ${data}`);
      });

      ffmpeg.on('close', (code) => {
        if (code !== 0) {
          console.error(`‚ùå Erreur FFmpeg (interm√©diaire): code ${code}`);
          console.error(`‚ùå FFmpeg stderr: ${stderr}`);
          reject(new Error(`ffmpeg error code: ${code}`));
          return;
        }
        console.log('‚úÖ Vid√©o interm√©diaire cr√©√©e avec succ√®s');
        resolve();
      });

      ffmpeg.on('error', (err) => {
        console.error('‚ùå Erreur lors de la cr√©ation de la vid√©o interm√©diaire:', err);
        reject(new Error(`Erreur FFmpeg: ${err.message}`));
      });

      if (options.timeout) {
        setTimeout(() => {
          ffmpeg.kill('SIGKILL');
          reject(new Error('Timeout lors de la cr√©ation de la vid√©o interm√©diaire'));
        }, options.timeout);
      }
    });
  }

  private concatWithPrefix1(prefix1Path: string, intermediatePath: string, outputPath: string, options: FFmpegOptions): Promise<void> {
    return new Promise((resolve, reject) => {
      console.log('üé¨ Concat√©nation avec prefix1...');

      const args = [
        '-i', prefix1Path,
        '-i', intermediatePath,
        '-filter_complex', '[0:v:0][0:a:0][1:v:0][1:a:0]concat=n=2:v=1:a=1[outv][outa]',
        '-map', '[outv]',
        '-map', '[outa]',
        '-c:v', 'libx264',
        '-c:a', 'aac',
        '-r', (options.fps || 25).toString(),
        '-crf', options.quality === 'low' ? '28' : options.quality === 'medium' ? '23' : '18',
        '-threads', (options.threads || 4).toString(),
        '-y',
        outputPath
      ];

      console.log('üé¨ Arguments FFmpeg (final):', args.join(' '));

      const ffmpeg = spawn('ffmpeg', args);

      let stderr = '';

      ffmpeg.stderr.on('data', (data) => {
        stderr += data.toString();
        console.log(`üé¨ FFmpeg (final): ${data}`);
      });

      ffmpeg.on('close', (code) => {
        if (code !== 0) {
          console.error(`‚ùå Erreur FFmpeg (final): code ${code}`);
          console.error(`‚ùå FFmpeg stderr: ${stderr}`);
          reject(new Error(`ffmpeg error code: ${code}`));
          return;
        }
        console.log('‚úÖ Concat√©nation finale termin√©e avec succ√®s');
        resolve();
      });

      ffmpeg.on('error', (err) => {
        console.error('‚ùå Erreur lors de la concat√©nation finale:', err);
        reject(new Error(`Erreur FFmpeg: ${err.message}`));
      });

      if (options.timeout) {
        setTimeout(() => {
          ffmpeg.kill('SIGKILL');
          reject(new Error('Timeout lors de la concat√©nation finale'));
        }, options.timeout);
      }
    });
  }

  private async getTargetDimensions(videoPath: string): Promise<{ width: number; height: number }> {
    try {
      const videoInfo = await this.getVideoInfo(videoPath);
      return {
        width: videoInfo.width,
        height: videoInfo.height
      };
    } catch (error) {
      console.error('‚ùå Erreur lors de l\'analyse des dimensions:', error);
      // Dimensions par d√©faut adapt√©es aux t√©l√©phones (mode portrait)
      return { width: 720, height: 1280 };
    }
  }

  private async adaptVideoDimensions(
    videoPath: string, 
    targetDimensions: { width: number; height: number }, 
    jobId: string,
    prefix: string
  ): Promise<string> {
    try {
      console.log(`üìê Adaptation des dimensions pour ${prefix}: ${targetDimensions.width}x${targetDimensions.height}`);
      
      const videoInfo = await this.getVideoInfo(videoPath);
      const currentWidth = videoInfo.width;
      const currentHeight = videoInfo.height;
      
      // V√©rifier si l'adaptation est n√©cessaire
      if (currentWidth === targetDimensions.width && currentHeight === targetDimensions.height) {
        console.log(`‚úÖ Dimensions d√©j√† compatibles pour ${prefix}, pas d'adaptation n√©cessaire`);
        return videoPath;
      }
      
      const adaptedPath = path.join(this.tempPath, `adapted_${prefix}_${jobId}.mp4`);
      
      return new Promise((resolve, reject) => {
        const args = [
          '-i', videoPath,
          '-filter_complex', this.buildAdaptationFilter(currentWidth, currentHeight, targetDimensions),
          '-c:v', 'libx264',
          '-c:a', 'aac',
          '-crf', '18',
          '-preset', 'medium',
          '-y',
          adaptedPath
        ];
        
        const ffmpeg = spawn('ffmpeg', args);
        
        ffmpeg.stderr.on('data', (data) => {
          console.log(`üìê Adaptation FFmpeg pour ${prefix}: ${data}`);
        });
        
        ffmpeg.on('close', (code) => {
          if (code !== 0) {
            console.error(`‚ùå Erreur lors de l'adaptation des dimensions pour ${prefix}: code ${code}`);
            reject(new Error(`Erreur FFmpeg lors de l'adaptation pour ${prefix}: ${code}`));
            return;
          }
          console.log(`‚úÖ Adaptation des dimensions termin√©e pour ${prefix}`);
          resolve(adaptedPath);
        });
        
        ffmpeg.on('error', (err) => {
          console.error(`‚ùå Erreur FFmpeg lors de l'adaptation pour ${prefix}:`, err);
          reject(new Error(`Erreur FFmpeg: ${err.message}`));
        });
      });
      
    } catch (error) {
      console.error(`‚ùå Erreur lors de l'adaptation des dimensions pour ${prefix}:`, error);
      // En cas d'erreur, retourner le chemin original
      return videoPath;
    }
  }

  private buildAdaptationFilter(
    currentWidth: number, 
    currentHeight: number, 
    targetDimensions: { width: number; height: number }
  ): string {
    const { width: targetWidth, height: targetHeight } = targetDimensions;
    
    // Calculer le ratio d'aspect
    const currentRatio = currentWidth / currentHeight;
    const targetRatio = targetWidth / targetHeight;
    
    if (currentRatio > targetRatio) {
      // Vid√©o plus large que la cible - redimensionner et ajouter du padding vertical
      return `scale=${targetWidth}:-2,pad=${targetWidth}:${targetHeight}:(ow-iw)/2:(oh-ih)/2:black,setsar=1`;
    } else if (currentRatio < targetRatio) {
      // Vid√©o plus haute que la cible - redimensionner et ajouter du padding horizontal
      return `scale=-2:${targetHeight},pad=${targetWidth}:${targetHeight}:(ow-iw)/2:(oh-ih)/2:black,setsar=1`;
    } else {
      // M√™me ratio - redimensionner simplement
      return `scale=${targetWidth}:${targetHeight},setsar=1`;
    }
  }

  async getJobStatus(jobId: string): Promise<JobStatus | null> {
    return this.jobs.get(jobId) || null;
  }

  async cleanupJob(jobId: string): Promise<void> {
    this.jobs.delete(jobId);
  }

  private async cleanupTempFiles(filePaths: string[]): Promise<void> {
    for (const filePath of filePaths) {
      await this.supabaseService.cleanupLocalFile(filePath);
    }
  }

  async cleanupOldFiles(maxAge: number = 24 * 60 * 60 * 1000): Promise<void> {
    const now = Date.now();
    
    // Nettoyer les jobs anciens
    for (const [jobId, job] of this.jobs.entries()) {
      if (now - job.updatedAt.getTime() > maxAge) {
        await this.cleanupJob(jobId);
      }
    }

    // Nettoyer les fichiers temporaires
    try {
      const tempFiles = await fs.readdir(this.tempPath);
      for (const file of tempFiles) {
        const filePath = path.join(this.tempPath, file);
        const stats = await fs.stat(filePath);
        if (now - stats.mtime.getTime() > maxAge) {
          await fs.remove(filePath);
        }
      }
    } catch (error) {
      console.error('Erreur lors du nettoyage des fichiers temporaires:', error);
    }
  }

  async uploadToSupabase(localFilePath: string, bucketName: string, destinationPath: string): Promise<void> {
    try {
      console.log('üì§ D√©but de l\'upload vers Supabase:', { localFilePath, bucketName, destinationPath });

      // V√©rifier que le fichier local existe
      if (!await fs.pathExists(localFilePath)) {
        throw new Error(`Fichier local non trouv√©: ${localFilePath}`);
      }

      // Uploader le fichier vers Supabase
      await this.supabaseService.upload(bucketName, localFilePath, destinationPath);

      console.log('‚úÖ Upload vers Supabase termin√©:', { destinationPath });

    } catch (error) {
      console.error('‚ùå Erreur lors de l\'upload vers Supabase:', error);
      throw error;
    }
  }



  private async processVideoFields(
    request: MergeRequest, 
    jobId: string
  ): Promise<MergeResponse> {
    const job = this.jobs.get(jobId);
    if (!job) {
      throw new Error('Job non trouv√©');
    }

    try {
      console.log('üé¨ D√©but du traitement vid√©o de pr√©sentation');

      // G√©n√©rer les chemins locaux
      const suffix = '_presentation';
      const prefixVideo1Path = path.join(this.tempPath, `prefix1${suffix}_${jobId}.mp4`);
      const prefixVideo2Path = path.join(this.tempPath, `prefix2${suffix}_${jobId}.mp4`);
      const postfixPath = path.join(this.tempPath, `postfix${suffix}_${jobId}.mp4`);
      const audioPath = request.audioBucketPath ? path.join(this.tempPath, `audio${suffix}_${jobId}.mp3`) : undefined;
      const outputPath = path.join(this.tempPath, `merged${suffix}_${jobId}.mp4`);

      // Mettre √† jour le statut
      job.status = 'processing';
      job.progress = 10;
      job.updatedAt = new Date();

      // T√©l√©charger l'audio si fourni
      if (request.audioBucketPath && audioPath) {
        console.log('üéµ T√©l√©chargement de l\'audio...');
        await this.supabaseService.download(SOUND_BUCKET, request.audioBucketPath, audioPath);
        job.progress = 50;
        job.updatedAt = new Date();
      }

      // T√©l√©charger les vid√©os depuis Supabase
      console.log('üì• T√©l√©chargement des vid√©os...');
      await this.supabaseService.download(VIDEO_BUCKET, request.prefixVideo1BucketPath, prefixVideo1Path);
      job.progress = 20;
      job.updatedAt = new Date();

      await this.supabaseService.download(VIDEO_BUCKET, request.prefixVideo2BucketPath, prefixVideo2Path);
      job.progress = 30;
      job.updatedAt = new Date();

      // Extraire le chemin du fichier depuis l'URL publique
      const urlParts = request.postfixVideoUrl.split('/');
      const filePath = urlParts.slice(-2).join('/'); // Prend les 2 derniers segments
      
      await this.supabaseService.download(VIDEO_BUCKET, filePath, postfixPath);
      job.progress = 40;
      job.updatedAt = new Date();

      // Analyser les dimensions des vid√©os et adapter la vid√©o postfixe
      console.log('üìê Analyse des dimensions des vid√©os...');
      const targetDimensions = await this.getTargetDimensions(prefixVideo1Path);
      
      // Adapter toutes les vid√©os aux m√™mes dimensions
      const adaptedPrefix1Path = await this.adaptVideoDimensions(prefixVideo1Path, targetDimensions, jobId, `prefix1${suffix}`);
      const adaptedPrefix2Path = await this.adaptVideoDimensions(prefixVideo2Path, targetDimensions, jobId, `prefix2${suffix}`);
      const adaptedPostfixPath = await this.adaptVideoDimensions(postfixPath, targetDimensions, jobId, `postfix${suffix}`);
      
      job.progress = 45;
      job.updatedAt = new Date();

      // Pr√©parer les options FFmpeg
      const ffmpegOptions: FFmpegOptions = {
        prefixVideo1Path: adaptedPrefix1Path,
        prefixVideo2Path: adaptedPrefix2Path,
        postfixPath: adaptedPostfixPath,
        outputPath,
        quality: request.quality,
        resolution: request.resolution,
        fps: request.fps,
        audioCodec: request.audioCodec,
        videoCodec: request.videoCodec,
        threads: parseInt(process.env['FFMPEG_THREADS'] || '4'),
        timeout: parseInt(process.env['FFMPEG_TIMEOUT'] || '300000'),
        metadata: request.metadata as any,
      };

      // Ajouter l'audio si disponible
      if (audioPath) {
        ffmpegOptions.audioPath = audioPath;
      }

      await this.executeTwoStepMerge(ffmpegOptions, jobId);
      
      job.progress = 80;
      job.updatedAt = new Date();

      // V√©rifier que le fichier de sortie existe
      if (!await fs.pathExists(outputPath)) {
        throw new Error('Le fichier de sortie n\'a pas √©t√© cr√©√©');
      }

      // Nettoyer les fichiers temporaires
      const tempFiles = [prefixVideo1Path, prefixVideo2Path, postfixPath, outputPath];
      if (audioPath) {
        tempFiles.push(audioPath);
      }
      // Ajouter les fichiers adapt√©s s'ils sont diff√©rents des originaux
      if (adaptedPrefix1Path !== prefixVideo1Path) {
        tempFiles.push(adaptedPrefix1Path);
      }
      if (adaptedPrefix2Path !== prefixVideo2Path) {
        tempFiles.push(adaptedPrefix2Path);
      }
      if (adaptedPostfixPath !== postfixPath) {
        tempFiles.push(adaptedPostfixPath);
      }
      // Ajouter la vid√©o interm√©diaire si elle existe
      if (audioPath) {
        const intermediatePath = path.join(this.tempPath, `intermediate${suffix}_${jobId}.mp4`);
        tempFiles.push(intermediatePath);
      }
      await this.cleanupTempFiles(tempFiles);

      // Mettre √† jour le job
      job.status = 'completed';
      job.progress = 100;
      job.outputUrl = outputPath;
      job.updatedAt = new Date();

      console.log('‚úÖ Traitement vid√©o de pr√©sentation termin√© avec succ√®s:', outputPath);

      return {
        success: true,
        outputUrl: outputPath,
        jobId
      };

    } catch (error) {
      // Mettre √† jour le job en cas d'erreur
      job.status = 'failed';
      job.error = error instanceof Error ? error.message : 'Erreur inconnue';
      job.updatedAt = new Date();

      console.error(`‚ùå Erreur lors du traitement vid√©o:`, error);

      return {
        success: false,
        error: error instanceof Error ? error.message : 'Erreur inconnue',
        jobId
      };
    }
  }


} 